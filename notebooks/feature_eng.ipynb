{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load the data\n",
    "data = {\n",
    "    \"eod_balance_training\": pd.read_csv(\n",
    "        \"gs://berkabank/production/data/04_processing/eod_balance_training.csv\"\n",
    "    ),\n",
    "    \"incidents\": pd.read_csv(\n",
    "        \"gs://berkabank/production/data/03_primary/incidents.csv\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eod_balance_training\n",
      "\n",
      "\n",
      "incidents\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    print(key)\n",
    "    data[key].to_csv(f\"../berkabank/primary/{key}.csv\",index=False) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['account_id', 'balance_date', 'end_of_day_balance', 'daily_amount_flow',\n",
       "       'n_transactions', 'days_since_account_creation', 'low_balance_streak',\n",
       "       'district_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"eod_balance_training\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Callable\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IncidentFeatures:\n",
    "    incidents: pd.DataFrame\n",
    "    column_mapping: dict\n",
    "\n",
    "    def run(self):\n",
    "        print(\"----- Running IncidentFeatures...\")\n",
    "        incident_features = pd.DataFrame()\n",
    "        print(\"----- IncidentFeatures completed.\")\n",
    "        return incident_features\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EODBFeatures:\n",
    "    eod_balance_training: pd.DataFrame\n",
    "    column_mapping: dict\n",
    "    aggregations:dict\n",
    "\n",
    "    def run(self):\n",
    "        print(\"----- Running EODBFeatures...\")\n",
    "        eodb_features_output = pd.DataFrame()\n",
    "        print(\"----- EODBFeatures completed.\")\n",
    "        return eodb_features_output\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PrimaryFeatures:\n",
    "    incident_features: IncidentFeatures\n",
    "    eodb_features: EODBFeatures\n",
    "\n",
    "    def __post_init__(self):\n",
    "        print(\"--- Initializing PrimaryFeatures...\")\n",
    "        self.incident_features_output = self.incident_features.run()\n",
    "        self.eodb_features_output = self.eodb_features.run()\n",
    "        print(\"--- PrimaryFeatures initialized.\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"--- Running PrimaryFeatures...\")\n",
    "        primary_features_output = pd.DataFrame()\n",
    "        print(\"--- PrimaryFeatures completed.\")\n",
    "        return primary_features_output\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DerivedFeatures:\n",
    "    primary_features: PrimaryFeatures\n",
    "\n",
    "    def __post_init__(self):\n",
    "        print(\"--- Initializing DerivedFeatures...\")\n",
    "        self.primary_features_output = self.primary_features.run()\n",
    "        print(\"--- DerivedFeatures initialized.\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"--- Running DerivedFeatures...\")\n",
    "        derived_features = pd.DataFrame()\n",
    "        print(\"--- DerivedFeatures completed.\")\n",
    "        return derived_features\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureEngineering:\n",
    "    primary_features: PrimaryFeatures\n",
    "    derived_features: DerivedFeatures\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Running FeatureEngineering...\")\n",
    "        self.derived_features.run()\n",
    "        print(\"FeatureEngineering completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class EODBFeatures:\n",
    "    eod_balance_training: pd.DataFrame\n",
    "    column_mapping: dict\n",
    "    aggregations:dict\n",
    "\n",
    "    def run(self):\n",
    "        print(\"----- Running EODBFeatures...\")\n",
    "        eodb_features_output = pd.DataFrame()\n",
    "        \n",
    "        print(\"----- EODBFeatures completed.\")\n",
    "        return eodb_features_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"incidents\":{\n",
    "        \"account_id\": \"account_id\",\n",
    "        \"incident_date\": \"incident_date\",\n",
    "        \"district_id\": \"district_id\",\n",
    "        \"t0\": \"t0\",\n",
    "        \"t1\": \"t1\",\n",
    "    },\n",
    "    \"eod_balance_training\":{\n",
    "        \"account_id\": \"account_id\",\n",
    "        \"balance_date\": \"balance_date\",\n",
    "        \"end_of_day_balance\": \"end_of_day_balance\",\n",
    "        \"daily_amount_flow\": \"daily_amount_flow\",\n",
    "        \"n_transactions\": \"n_transactions\",\n",
    "        \"days_since_account_creation\": \"days_since_account_creation\",\n",
    "        \"low_balance_streak\": \"low_balance_streak\",\n",
    "        \"district_id\": \"district_id\",\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "aggregations = {\n",
    "    \"time_periods_days\":[str(i) for i in range(1, 31)],\n",
    "    \"functions\" : [\"mean\", \"std\", \"min\", \"max\", \"sum\"],\n",
    "    \"columns\": [\"end_of_day_balance\" , \"daily_amount_flow\", \"n_transactions\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[\"eod_balance_training\"].loc[:,[\"account_id\",\"balance_date\",\"end_of_day_balance\" , \"daily_amount_flow\", \"n_transactions\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>balance_date</th>\n",
       "      <th>end_of_day_balance</th>\n",
       "      <th>daily_amount_flow</th>\n",
       "      <th>n_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-11</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>6207.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-12</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-13</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-14</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-15</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id balance_date  end_of_day_balance  daily_amount_flow  \\\n",
       "0         576   1993-01-11              7107.0             6207.0   \n",
       "1         576   1993-01-12              7107.0                0.0   \n",
       "2         576   1993-01-13              7107.0                0.0   \n",
       "3         576   1993-01-14              7107.0                0.0   \n",
       "4         576   1993-01-15              7107.0                0.0   \n",
       "\n",
       "   n_transactions  \n",
       "0             1.0  \n",
       "1             1.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing PrimaryFeatures...\n",
      "----- Running IncidentFeatures...\n",
      "----- IncidentFeatures completed.\n",
      "----- Running EODBFeatures...\n",
      "----- EODBFeatures completed.\n",
      "--- PrimaryFeatures initialized.\n",
      "--- Initializing DerivedFeatures...\n",
      "--- Running PrimaryFeatures...\n",
      "--- PrimaryFeatures completed.\n",
      "--- DerivedFeatures initialized.\n",
      "Running FeatureEngineering...\n",
      "--- Running DerivedFeatures...\n",
      "--- DerivedFeatures completed.\n",
      "FeatureEngineering completed.\n"
     ]
    }
   ],
   "source": [
    "# Configure each class with specific parameters\n",
    "incident_features = IncidentFeatures(data[\"incidents\"], column_mapping[\"incidents\"])\n",
    "eodb_features = EODBFeatures(\n",
    "    data[\"eod_balance_training\"], column_mapping[\"eod_balance_training\"],aggregations\n",
    ")\n",
    "primary_features = PrimaryFeatures(\n",
    "   \n",
    "    incident_features,\n",
    "    eodb_features,\n",
    ")\n",
    "derived_features = DerivedFeatures(primary_features)\n",
    "\n",
    "# Run the FeatureEngineering pipeline\n",
    "feature_engineering = FeatureEngineering(primary_features, derived_features)\n",
    "features = feature_engineering.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688119, 5)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[\"eod_balance_training\"].loc[:,[\"account_id\",\"balance_date\",\"end_of_day_balance\" , \"daily_amount_flow\", \"n_transactions\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/1905528839.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class EODBFeatures:\n",
    "    eod_balance_training: pd.DataFrame\n",
    "    column_mapping: dict\n",
    "    aggregations: List[str]\n",
    "\n",
    "    def run(self):\n",
    "        print(\"----- Running EODBFeatures...\")\n",
    "        eodb_features_output = pd.DataFrame()\n",
    "        print(\"----- EODBFeatures completed.\")\n",
    "        return eodb_features_output\n",
    "    \n",
    "\n",
    "\n",
    "# Create independent rolling statistics for each account by time period\n",
    "max_t = 20\n",
    "min_t = 5\n",
    "time_periods_days = [i for i in range(min_t, max_t+1)]\n",
    "agg_funcs = [\"mean\", \"max\", \"sum\" , \"std\", \"median\" ]\n",
    "category = ['inflow', 'outflow']\n",
    "feature = 'daily_amount_flow'\n",
    "\n",
    "aggregations = []\n",
    "df['flow_category'] = (df['daily_amount_flow'] > 0).astype(str).replace({'True': 'inflow', 'False': 'outflow'})\n",
    "for time_period in time_periods_days:\n",
    "    for func in agg_funcs:\n",
    "        for cat in category:\n",
    "            naming_f = f'f_{feature}__{cat}_rolling_{func}_{time_period}_days'\n",
    "            df[naming_f] = df.loc[df['flow_category'] == cat,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
    "            if cat == 'outflow':\n",
    "                df[naming_f] = df[naming_f].abs()\n",
    "            aggregations.append(naming_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = aggregations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregations(max_t:int = 20, min_t:int = 5, agg_funcs:List[str] = [\"mean\", \"max\", \"sum\" , \"std\", \"median\"], category:List[str] = ['inflow', 'outflow'], features:List[str] = ['daily_amount_flow']):\n",
    "    time_periods_days = [i for i in range(min_t, max_t+1)]\n",
    "    aggregations = []\n",
    "    for feature in features:\n",
    "        for time_period in time_periods_days:\n",
    "            for func in agg_funcs:\n",
    "                for cat in category:\n",
    "                    naming_f = f'f_{feature}__{cat}_rolling_{func}_{time_period}_days'\n",
    "                    aggregations.append(naming_f)\n",
    "    return aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_aggregations(df:pd.DataFrame, agg_funcs:List[str]):\n",
    "    df['flow_category'] = (df['daily_amount_flow'] > 0).astype(str).replace({'True': 'inflow', 'False': 'outflow'})\n",
    "    for aggregation in agg_funcs:\n",
    "        parts = aggregation.split('__')\n",
    "        feature = parts[0][2:]\n",
    "        category = parts[1].split('_rolling_')[0]\n",
    "        func = parts[1].split('_rolling_')[1].split('_')[0]\n",
    "        time_period = int(parts[1].split('_rolling_')[1].split('_')[1])\n",
    "        df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
    "        if category == 'outflow':\n",
    "            df[aggregation] = df[aggregation].abs()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_5_days\n",
      "daily_amount_flow inflow mean 5\n",
      "f_daily_amount_flow__outflow_rolling_mean_5_days\n",
      "daily_amount_flow outflow mean 5\n",
      "f_daily_amount_flow__inflow_rolling_max_5_days\n",
      "daily_amount_flow inflow max 5\n",
      "f_daily_amount_flow__outflow_rolling_max_5_days\n",
      "daily_amount_flow outflow max 5\n",
      "f_daily_amount_flow__inflow_rolling_sum_5_days\n",
      "daily_amount_flow inflow sum 5\n",
      "f_daily_amount_flow__outflow_rolling_sum_5_days\n",
      "daily_amount_flow outflow sum 5\n",
      "f_daily_amount_flow__inflow_rolling_std_5_days\n",
      "daily_amount_flow inflow std 5\n",
      "f_daily_amount_flow__outflow_rolling_std_5_days\n",
      "daily_amount_flow outflow std 5\n",
      "f_daily_amount_flow__inflow_rolling_median_5_days\n",
      "daily_amount_flow inflow median 5\n",
      "f_daily_amount_flow__outflow_rolling_median_5_days\n",
      "daily_amount_flow outflow median 5\n",
      "f_daily_amount_flow__inflow_rolling_mean_6_days\n",
      "daily_amount_flow inflow mean 6\n",
      "f_daily_amount_flow__outflow_rolling_mean_6_days\n",
      "daily_amount_flow outflow mean 6\n",
      "f_daily_amount_flow__inflow_rolling_max_6_days\n",
      "daily_amount_flow inflow max 6\n",
      "f_daily_amount_flow__outflow_rolling_max_6_days\n",
      "daily_amount_flow outflow max 6\n",
      "f_daily_amount_flow__inflow_rolling_sum_6_days\n",
      "daily_amount_flow inflow sum 6\n",
      "f_daily_amount_flow__outflow_rolling_sum_6_days\n",
      "daily_amount_flow outflow sum 6\n",
      "f_daily_amount_flow__inflow_rolling_std_6_days\n",
      "daily_amount_flow inflow std 6\n",
      "f_daily_amount_flow__outflow_rolling_std_6_days\n",
      "daily_amount_flow outflow std 6\n",
      "f_daily_amount_flow__inflow_rolling_median_6_days\n",
      "daily_amount_flow inflow median 6\n",
      "f_daily_amount_flow__outflow_rolling_median_6_days\n",
      "daily_amount_flow outflow median 6\n",
      "f_daily_amount_flow__inflow_rolling_mean_7_days\n",
      "daily_amount_flow inflow mean 7\n",
      "f_daily_amount_flow__outflow_rolling_mean_7_days\n",
      "daily_amount_flow outflow mean 7\n",
      "f_daily_amount_flow__inflow_rolling_max_7_days\n",
      "daily_amount_flow inflow max 7\n",
      "f_daily_amount_flow__outflow_rolling_max_7_days\n",
      "daily_amount_flow outflow max 7\n",
      "f_daily_amount_flow__inflow_rolling_sum_7_days\n",
      "daily_amount_flow inflow sum 7\n",
      "f_daily_amount_flow__outflow_rolling_sum_7_days\n",
      "daily_amount_flow outflow sum 7\n",
      "f_daily_amount_flow__inflow_rolling_std_7_days\n",
      "daily_amount_flow inflow std 7\n",
      "f_daily_amount_flow__outflow_rolling_std_7_days\n",
      "daily_amount_flow outflow std 7\n",
      "f_daily_amount_flow__inflow_rolling_median_7_days\n",
      "daily_amount_flow inflow median 7\n",
      "f_daily_amount_flow__outflow_rolling_median_7_days\n",
      "daily_amount_flow outflow median 7\n",
      "f_daily_amount_flow__inflow_rolling_mean_8_days\n",
      "daily_amount_flow inflow mean 8\n",
      "f_daily_amount_flow__outflow_rolling_mean_8_days\n",
      "daily_amount_flow outflow mean 8\n",
      "f_daily_amount_flow__inflow_rolling_max_8_days\n",
      "daily_amount_flow inflow max 8\n",
      "f_daily_amount_flow__outflow_rolling_max_8_days\n",
      "daily_amount_flow outflow max 8\n",
      "f_daily_amount_flow__inflow_rolling_sum_8_days\n",
      "daily_amount_flow inflow sum 8\n",
      "f_daily_amount_flow__outflow_rolling_sum_8_days\n",
      "daily_amount_flow outflow sum 8\n",
      "f_daily_amount_flow__inflow_rolling_std_8_days\n",
      "daily_amount_flow inflow std 8\n",
      "f_daily_amount_flow__outflow_rolling_std_8_days\n",
      "daily_amount_flow outflow std 8\n",
      "f_daily_amount_flow__inflow_rolling_median_8_days\n",
      "daily_amount_flow inflow median 8\n",
      "f_daily_amount_flow__outflow_rolling_median_8_days\n",
      "daily_amount_flow outflow median 8\n",
      "f_daily_amount_flow__inflow_rolling_mean_9_days\n",
      "daily_amount_flow inflow mean 9\n",
      "f_daily_amount_flow__outflow_rolling_mean_9_days\n",
      "daily_amount_flow outflow mean 9\n",
      "f_daily_amount_flow__inflow_rolling_max_9_days\n",
      "daily_amount_flow inflow max 9\n",
      "f_daily_amount_flow__outflow_rolling_max_9_days\n",
      "daily_amount_flow outflow max 9\n",
      "f_daily_amount_flow__inflow_rolling_sum_9_days\n",
      "daily_amount_flow inflow sum 9\n",
      "f_daily_amount_flow__outflow_rolling_sum_9_days\n",
      "daily_amount_flow outflow sum 9\n",
      "f_daily_amount_flow__inflow_rolling_std_9_days\n",
      "daily_amount_flow inflow std 9\n",
      "f_daily_amount_flow__outflow_rolling_std_9_days\n",
      "daily_amount_flow outflow std 9\n",
      "f_daily_amount_flow__inflow_rolling_median_9_days\n",
      "daily_amount_flow inflow median 9\n",
      "f_daily_amount_flow__outflow_rolling_median_9_days\n",
      "daily_amount_flow outflow median 9\n",
      "f_daily_amount_flow__inflow_rolling_mean_10_days\n",
      "daily_amount_flow inflow mean 10\n",
      "f_daily_amount_flow__outflow_rolling_mean_10_days\n",
      "daily_amount_flow outflow mean 10\n",
      "f_daily_amount_flow__inflow_rolling_max_10_days\n",
      "daily_amount_flow inflow max 10\n",
      "f_daily_amount_flow__outflow_rolling_max_10_days\n",
      "daily_amount_flow outflow max 10\n",
      "f_daily_amount_flow__inflow_rolling_sum_10_days\n",
      "daily_amount_flow inflow sum 10\n",
      "f_daily_amount_flow__outflow_rolling_sum_10_days\n",
      "daily_amount_flow outflow sum 10\n",
      "f_daily_amount_flow__inflow_rolling_std_10_days\n",
      "daily_amount_flow inflow std 10\n",
      "f_daily_amount_flow__outflow_rolling_std_10_days\n",
      "daily_amount_flow outflow std 10\n",
      "f_daily_amount_flow__inflow_rolling_median_10_days\n",
      "daily_amount_flow inflow median 10\n",
      "f_daily_amount_flow__outflow_rolling_median_10_days\n",
      "daily_amount_flow outflow median 10\n",
      "f_daily_amount_flow__inflow_rolling_mean_11_days\n",
      "daily_amount_flow inflow mean 11\n",
      "f_daily_amount_flow__outflow_rolling_mean_11_days\n",
      "daily_amount_flow outflow mean 11\n",
      "f_daily_amount_flow__inflow_rolling_max_11_days\n",
      "daily_amount_flow inflow max 11\n",
      "f_daily_amount_flow__outflow_rolling_max_11_days\n",
      "daily_amount_flow outflow max 11\n",
      "f_daily_amount_flow__inflow_rolling_sum_11_days\n",
      "daily_amount_flow inflow sum 11\n",
      "f_daily_amount_flow__outflow_rolling_sum_11_days\n",
      "daily_amount_flow outflow sum 11\n",
      "f_daily_amount_flow__inflow_rolling_std_11_days\n",
      "daily_amount_flow inflow std 11\n",
      "f_daily_amount_flow__outflow_rolling_std_11_days\n",
      "daily_amount_flow outflow std 11\n",
      "f_daily_amount_flow__inflow_rolling_median_11_days\n",
      "daily_amount_flow inflow median 11\n",
      "f_daily_amount_flow__outflow_rolling_median_11_days\n",
      "daily_amount_flow outflow median 11\n",
      "f_daily_amount_flow__inflow_rolling_mean_12_days\n",
      "daily_amount_flow inflow mean 12\n",
      "f_daily_amount_flow__outflow_rolling_mean_12_days\n",
      "daily_amount_flow outflow mean 12\n",
      "f_daily_amount_flow__inflow_rolling_max_12_days\n",
      "daily_amount_flow inflow max 12\n",
      "f_daily_amount_flow__outflow_rolling_max_12_days\n",
      "daily_amount_flow outflow max 12\n",
      "f_daily_amount_flow__inflow_rolling_sum_12_days\n",
      "daily_amount_flow inflow sum 12\n",
      "f_daily_amount_flow__outflow_rolling_sum_12_days\n",
      "daily_amount_flow outflow sum 12\n",
      "f_daily_amount_flow__inflow_rolling_std_12_days\n",
      "daily_amount_flow inflow std 12\n",
      "f_daily_amount_flow__outflow_rolling_std_12_days\n",
      "daily_amount_flow outflow std 12\n",
      "f_daily_amount_flow__inflow_rolling_median_12_days\n",
      "daily_amount_flow inflow median 12\n",
      "f_daily_amount_flow__outflow_rolling_median_12_days\n",
      "daily_amount_flow outflow median 12\n",
      "f_daily_amount_flow__inflow_rolling_mean_13_days\n",
      "daily_amount_flow inflow mean 13\n",
      "f_daily_amount_flow__outflow_rolling_mean_13_days\n",
      "daily_amount_flow outflow mean 13\n",
      "f_daily_amount_flow__inflow_rolling_max_13_days\n",
      "daily_amount_flow inflow max 13\n",
      "f_daily_amount_flow__outflow_rolling_max_13_days\n",
      "daily_amount_flow outflow max 13\n",
      "f_daily_amount_flow__inflow_rolling_sum_13_days\n",
      "daily_amount_flow inflow sum 13\n",
      "f_daily_amount_flow__outflow_rolling_sum_13_days\n",
      "daily_amount_flow outflow sum 13\n",
      "f_daily_amount_flow__inflow_rolling_std_13_days\n",
      "daily_amount_flow inflow std 13\n",
      "f_daily_amount_flow__outflow_rolling_std_13_days\n",
      "daily_amount_flow outflow std 13\n",
      "f_daily_amount_flow__inflow_rolling_median_13_days\n",
      "daily_amount_flow inflow median 13\n",
      "f_daily_amount_flow__outflow_rolling_median_13_days\n",
      "daily_amount_flow outflow median 13\n",
      "f_daily_amount_flow__inflow_rolling_mean_14_days\n",
      "daily_amount_flow inflow mean 14\n",
      "f_daily_amount_flow__outflow_rolling_mean_14_days\n",
      "daily_amount_flow outflow mean 14\n",
      "f_daily_amount_flow__inflow_rolling_max_14_days\n",
      "daily_amount_flow inflow max 14\n",
      "f_daily_amount_flow__outflow_rolling_max_14_days\n",
      "daily_amount_flow outflow max 14\n",
      "f_daily_amount_flow__inflow_rolling_sum_14_days\n",
      "daily_amount_flow inflow sum 14\n",
      "f_daily_amount_flow__outflow_rolling_sum_14_days\n",
      "daily_amount_flow outflow sum 14\n",
      "f_daily_amount_flow__inflow_rolling_std_14_days\n",
      "daily_amount_flow inflow std 14\n",
      "f_daily_amount_flow__outflow_rolling_std_14_days\n",
      "daily_amount_flow outflow std 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_14_days\n",
      "daily_amount_flow inflow median 14\n",
      "f_daily_amount_flow__outflow_rolling_median_14_days\n",
      "daily_amount_flow outflow median 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_15_days\n",
      "daily_amount_flow inflow mean 15\n",
      "f_daily_amount_flow__outflow_rolling_mean_15_days\n",
      "daily_amount_flow outflow mean 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_15_days\n",
      "daily_amount_flow inflow max 15\n",
      "f_daily_amount_flow__outflow_rolling_max_15_days\n",
      "daily_amount_flow outflow max 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_15_days\n",
      "daily_amount_flow inflow sum 15\n",
      "f_daily_amount_flow__outflow_rolling_sum_15_days\n",
      "daily_amount_flow outflow sum 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_15_days\n",
      "daily_amount_flow inflow std 15\n",
      "f_daily_amount_flow__outflow_rolling_std_15_days\n",
      "daily_amount_flow outflow std 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_15_days\n",
      "daily_amount_flow inflow median 15\n",
      "f_daily_amount_flow__outflow_rolling_median_15_days\n",
      "daily_amount_flow outflow median 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_16_days\n",
      "daily_amount_flow inflow mean 16\n",
      "f_daily_amount_flow__outflow_rolling_mean_16_days\n",
      "daily_amount_flow outflow mean 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_16_days\n",
      "daily_amount_flow inflow max 16\n",
      "f_daily_amount_flow__outflow_rolling_max_16_days\n",
      "daily_amount_flow outflow max 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_16_days\n",
      "daily_amount_flow inflow sum 16\n",
      "f_daily_amount_flow__outflow_rolling_sum_16_days\n",
      "daily_amount_flow outflow sum 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_16_days\n",
      "daily_amount_flow inflow std 16\n",
      "f_daily_amount_flow__outflow_rolling_std_16_days\n",
      "daily_amount_flow outflow std 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_16_days\n",
      "daily_amount_flow inflow median 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_median_16_days\n",
      "daily_amount_flow outflow median 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_17_days\n",
      "daily_amount_flow inflow mean 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_mean_17_days\n",
      "daily_amount_flow outflow mean 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_17_days\n",
      "daily_amount_flow inflow max 17\n",
      "f_daily_amount_flow__outflow_rolling_max_17_days\n",
      "daily_amount_flow outflow max 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_17_days\n",
      "daily_amount_flow inflow sum 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_sum_17_days\n",
      "daily_amount_flow outflow sum 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_17_days\n",
      "daily_amount_flow inflow std 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_std_17_days\n",
      "daily_amount_flow outflow std 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_17_days\n",
      "daily_amount_flow inflow median 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_median_17_days\n",
      "daily_amount_flow outflow median 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_18_days\n",
      "daily_amount_flow inflow mean 18\n",
      "f_daily_amount_flow__outflow_rolling_mean_18_days\n",
      "daily_amount_flow outflow mean 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_18_days\n",
      "daily_amount_flow inflow max 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_max_18_days\n",
      "daily_amount_flow outflow max 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_18_days\n",
      "daily_amount_flow inflow sum 18\n",
      "f_daily_amount_flow__outflow_rolling_sum_18_days\n",
      "daily_amount_flow outflow sum 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_18_days\n",
      "daily_amount_flow inflow std 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_std_18_days\n",
      "daily_amount_flow outflow std 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_18_days\n",
      "daily_amount_flow inflow median 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_median_18_days\n",
      "daily_amount_flow outflow median 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_19_days\n",
      "daily_amount_flow inflow mean 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_mean_19_days\n",
      "daily_amount_flow outflow mean 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_19_days\n",
      "daily_amount_flow inflow max 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_max_19_days\n",
      "daily_amount_flow outflow max 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_19_days\n",
      "daily_amount_flow inflow sum 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_sum_19_days\n",
      "daily_amount_flow outflow sum 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_19_days\n",
      "daily_amount_flow inflow std 19\n",
      "f_daily_amount_flow__outflow_rolling_std_19_days\n",
      "daily_amount_flow outflow std 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n",
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_19_days\n",
      "daily_amount_flow inflow median 19\n",
      "f_daily_amount_flow__outflow_rolling_median_19_days\n",
      "daily_amount_flow outflow median 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_mean_20_days\n",
      "daily_amount_flow inflow mean 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_mean_20_days\n",
      "daily_amount_flow outflow mean 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_max_20_days\n",
      "daily_amount_flow inflow max 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_max_20_days\n",
      "daily_amount_flow outflow max 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_sum_20_days\n",
      "daily_amount_flow inflow sum 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_sum_20_days\n",
      "daily_amount_flow outflow sum 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_std_20_days\n",
      "daily_amount_flow inflow std 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_std_20_days\n",
      "daily_amount_flow outflow std 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__inflow_rolling_median_20_days\n",
      "daily_amount_flow inflow median 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_daily_amount_flow__outflow_rolling_median_20_days\n",
      "daily_amount_flow outflow median 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2v/jln6f4j122qcvxp2jjr6cclm0000gn/T/ipykernel_73300/802122447.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[aggregation] = df.loc[df['flow_category'] == category,:].groupby('account_id')[feature].rolling(time_period).agg(func).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>balance_date</th>\n",
       "      <th>end_of_day_balance</th>\n",
       "      <th>daily_amount_flow</th>\n",
       "      <th>n_transactions</th>\n",
       "      <th>flow_category</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_mean_5_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_mean_5_days</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_max_5_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_max_5_days</th>\n",
       "      <th>...</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_mean_20_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_mean_20_days</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_max_20_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_max_20_days</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_sum_20_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_sum_20_days</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_std_20_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_std_20_days</th>\n",
       "      <th>f_daily_amount_flow__inflow_rolling_median_20_days</th>\n",
       "      <th>f_daily_amount_flow__outflow_rolling_median_20_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-11</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>6207.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-12</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-13</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-14</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>1993-01-15</td>\n",
       "      <td>7107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688114</th>\n",
       "      <td>4375</td>\n",
       "      <td>1996-11-10</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688115</th>\n",
       "      <td>880</td>\n",
       "      <td>1996-12-08</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688116</th>\n",
       "      <td>880</td>\n",
       "      <td>1996-12-09</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688117</th>\n",
       "      <td>880</td>\n",
       "      <td>1996-12-10</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688118</th>\n",
       "      <td>880</td>\n",
       "      <td>1996-12-11</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>outflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688119 rows  166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        account_id balance_date  end_of_day_balance  daily_amount_flow  \\\n",
       "0              576   1993-01-11              7107.0             6207.0   \n",
       "1              576   1993-01-12              7107.0                0.0   \n",
       "2              576   1993-01-13              7107.0                0.0   \n",
       "3              576   1993-01-14              7107.0                0.0   \n",
       "4              576   1993-01-15              7107.0                0.0   \n",
       "...            ...          ...                 ...                ...   \n",
       "688114        4375   1996-11-10               800.0                0.0   \n",
       "688115         880   1996-12-08               700.0              700.0   \n",
       "688116         880   1996-12-09               700.0                0.0   \n",
       "688117         880   1996-12-10               700.0                0.0   \n",
       "688118         880   1996-12-11               700.0                0.0   \n",
       "\n",
       "        n_transactions flow_category  \\\n",
       "0                  1.0        inflow   \n",
       "1                  1.0       outflow   \n",
       "2                  1.0       outflow   \n",
       "3                  1.0       outflow   \n",
       "4                  1.0       outflow   \n",
       "...                ...           ...   \n",
       "688114             0.0       outflow   \n",
       "688115             0.0        inflow   \n",
       "688116             0.0       outflow   \n",
       "688117             0.0       outflow   \n",
       "688118             0.0       outflow   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_mean_5_days  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "688114                                              NaN   \n",
       "688115                                              NaN   \n",
       "688116                                              NaN   \n",
       "688117                                              NaN   \n",
       "688118                                              NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_mean_5_days  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "688114                                               0.0   \n",
       "688115                                               NaN   \n",
       "688116                                               NaN   \n",
       "688117                                               NaN   \n",
       "688118                                               NaN   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_max_5_days  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "...                                                ...   \n",
       "688114                                             NaN   \n",
       "688115                                             NaN   \n",
       "688116                                             NaN   \n",
       "688117                                             NaN   \n",
       "688118                                             NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_max_5_days  ...  \\\n",
       "0                                                   NaN  ...   \n",
       "1                                                   NaN  ...   \n",
       "2                                                   NaN  ...   \n",
       "3                                                   NaN  ...   \n",
       "4                                                   NaN  ...   \n",
       "...                                                 ...  ...   \n",
       "688114                                              0.0  ...   \n",
       "688115                                              NaN  ...   \n",
       "688116                                              NaN  ...   \n",
       "688117                                              NaN  ...   \n",
       "688118                                              NaN  ...   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_mean_20_days  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "688114                                               NaN   \n",
       "688115                                               NaN   \n",
       "688116                                               NaN   \n",
       "688117                                               NaN   \n",
       "688118                                               NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_mean_20_days  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "688114                                                NaN   \n",
       "688115                                                NaN   \n",
       "688116                                                NaN   \n",
       "688117                                                NaN   \n",
       "688118                                                NaN   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_max_20_days  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "688114                                              NaN   \n",
       "688115                                              NaN   \n",
       "688116                                              NaN   \n",
       "688117                                              NaN   \n",
       "688118                                              NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_max_20_days  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "688114                                               NaN   \n",
       "688115                                               NaN   \n",
       "688116                                               NaN   \n",
       "688117                                               NaN   \n",
       "688118                                               NaN   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_sum_20_days  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "688114                                              NaN   \n",
       "688115                                              NaN   \n",
       "688116                                              NaN   \n",
       "688117                                              NaN   \n",
       "688118                                              NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_sum_20_days  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "688114                                               NaN   \n",
       "688115                                               NaN   \n",
       "688116                                               NaN   \n",
       "688117                                               NaN   \n",
       "688118                                               NaN   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_std_20_days  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "688114                                              NaN   \n",
       "688115                                              NaN   \n",
       "688116                                              NaN   \n",
       "688117                                              NaN   \n",
       "688118                                              NaN   \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_std_20_days  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "688114                                               NaN   \n",
       "688115                                               NaN   \n",
       "688116                                               NaN   \n",
       "688117                                               NaN   \n",
       "688118                                               NaN   \n",
       "\n",
       "        f_daily_amount_flow__inflow_rolling_median_20_days  \\\n",
       "0                                                     NaN    \n",
       "1                                                     NaN    \n",
       "2                                                     NaN    \n",
       "3                                                     NaN    \n",
       "4                                                     NaN    \n",
       "...                                                   ...    \n",
       "688114                                                NaN    \n",
       "688115                                                NaN    \n",
       "688116                                                NaN    \n",
       "688117                                                NaN    \n",
       "688118                                                NaN    \n",
       "\n",
       "        f_daily_amount_flow__outflow_rolling_median_20_days  \n",
       "0                                                     NaN    \n",
       "1                                                     NaN    \n",
       "2                                                     NaN    \n",
       "3                                                     NaN    \n",
       "4                                                     NaN    \n",
       "...                                                   ...    \n",
       "688114                                                NaN    \n",
       "688115                                                NaN    \n",
       "688116                                                NaN    \n",
       "688117                                                NaN    \n",
       "688118                                                NaN    \n",
       "\n",
       "[688119 rows x 166 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_aggregations(df, aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
