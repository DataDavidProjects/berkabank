{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import json\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `project_id`: The ID of your Google Cloud project.\n",
    "- `location`: The region where your Vertex AI resources are located.\n",
    "- `model_resource_name`: The resource name of the model you want to use for batch prediction. This should be a fully qualified resource name that includes the project, location, and model ID.\n",
    "- `job_display_name`: The display name of the batch prediction job. This can be any string you choose.\n",
    "- `gcs_source`: The Google Cloud Storage (GCS) URI or URIs where your input data is stored. This can be a string (for a single URI) or a list of strings (for multiple URIs).\n",
    "- `gcs_destination`: The GCS URI where you want the output data to be stored.\n",
    "- `instances_format`: The format of the input data. This can be \"jsonl\", \"csv\", \"tf-record\", \"tf-record-gzip\", or \"file-list\".\n",
    "- `machine_type`: The type of machine to use for the batch prediction job. This should be a string that specifies a Compute Engine machine type, such as \"n1-standard-2\".\n",
    "- `accelerator_count`: The number of accelerators to attach to each machine.\n",
    "- `accelerator_type`: The type of accelerator to attach to each machine. This can be a string that specifies a Compute Engine accelerator type, such as \"NVIDIA_TESLA_K80\", or an `AcceleratorType` enum value.\n",
    "- `starting_replica_count`: The initial number of replicas to use for the batch prediction job.\n",
    "- `max_replica_count`: The maximum number of replicas to use for the batch prediction job.\n",
    "- `sync`: A boolean value that specifies whether to block until the batch prediction job is completed. If `True`, the function will block until the job is completed. If `False`, the function will return immediately after the job is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get(\"PROJECT_ID\")\n",
    "REGION = os.environ.get(\"REGION\")\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\")\n",
    "MODEL_NAME = \"berkamodel\"\n",
    "PIPELINE_NAME = \"production\"\n",
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "FILE_SCORING_NAME = \"training_drivers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/europe-west6/batch-predictions/5847697616745267200?project=1036389498447\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/1036389498447/locations/europe-west6/batchPredictionJobs/5847697616745267200\n"
     ]
    }
   ],
   "source": [
    "model_resource_name = f\"projects/{PROJECT_ID}/locations/{REGION}/models/{MODEL_NAME}\"\n",
    "job_display_name = f\"{MODEL_NAME}_batch_prediction_job\"\n",
    "gcs_source = f\"gs://{BUCKET_NAME}/{PIPELINE_NAME}/data/05_features/{FILE_SCORING_NAME}.csv\"\n",
    "gcs_destination = f\"gs://{BUCKET_NAME}/{PIPELINE_NAME}/data/07_output/\"\n",
    "instances_format = \"csv\"\n",
    "machine_type = \"n1-standard-2\"\n",
    "accelerator_count = 0\n",
    "accelerator_type = None\n",
    "starting_replica_count = 1\n",
    "max_replica_count = 1\n",
    "sync = True\n",
    "\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "def get_model_by_display_name(display_name, verbose=False):\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options={\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"})\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "    response = client.list_models(parent=parent)\n",
    "\n",
    "    for model in response:\n",
    "        if model.display_name == display_name:\n",
    "            if verbose:\n",
    "                print(f\"Model {display_name} found.\")\n",
    "                print(f\"Model details:\\n {model}\")\n",
    "            return model\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Define the details for the batch prediction job\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model_id = get_model_by_display_name(MODEL_NAME).name\n",
    "model_container = aiplatform.Model(model_id)\n",
    "\n",
    "batch_prediction_job = model_container.batch_predict(\n",
    "    job_display_name=job_display_name,\n",
    "    gcs_source=gcs_source,\n",
    "    gcs_destination_prefix=gcs_destination,\n",
    "    instances_format=instances_format,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    accelerator_type=accelerator_type,\n",
    "    starting_replica_count=starting_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    sync=sync,\n",
    ")\n",
    "\n",
    "batch_prediction_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
